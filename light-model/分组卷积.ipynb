{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分组卷积\n",
    "## 解决的问题\n",
    "+ 降低模型参数量和计算量\n",
    "## 解决方式\n",
    "+ 通道分组，每一组通道公用一个卷积核\n",
    "## 存在的问题\n",
    "+ 各组之间信息不流动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GConv(in_channel,out_channel,kernel_size,padding,stride,bias,groups):\n",
    "    return nn.Conv2d(in_channel, out_channel, kernel_size, padding=padding, groups=groups ,stride=stride, bias=bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度可分离卷积\n",
    "## 解决的问题\n",
    "+ 解决分离卷积导致的各个通道之间信息不流动\n",
    "## 解决方式\n",
    "+ 分组卷积之后加1X1卷积，加强通道之间信息传递\n",
    "## 存在的问题\n",
    "+ 每一个分组卷积之后都要进行一次点卷积，相当于人为加深模型深度\n",
    "+ 1X1卷积耗费大量的资源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "def DepthwiseConv(in_channel,out_channel,kernel_size,padding,stride,bias):\n",
    "    layers=list()\n",
    "    layers.append(nn.Conv2d(in_channel, in_channel, kernel_size, padding=padding, groups=in_channel ,stride=stride, bias=bias))\n",
    "    layers.append(nn.Conv2d(in_channel,out_channel,kernel_size=1))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shuffleNet\n",
    "## 解决的问题\n",
    "+ 解决深度可分离卷积中1X1占据资源问题\n",
    "## 解决方式\n",
    "+ 对于1X1卷积进一次使用分组卷积\n",
    "+ 加上channel shuffle，具体解释之后介绍\n",
    "## channel shuffle\n",
    "假定将输入层分为g组，总通道数为g*n，首先你将通道那个维度拆分为(g,n)两个维度，然后将这两个维度转置变成(n,g)，最后重新reshape成一个维度\n",
    "## 存在的问题\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img src=./img/channel_shuffle.png />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#使用的时候需要添加梯度剪切\n",
    "class ShuffleV1Block(nn.Module):\n",
    "\n",
    "    def __init__(self, inp, oup, mid_channels, group=4, ksize=3, stride=1):\n",
    "        super(ShuffleV1Block, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        self.mid_channels = mid_channels\n",
    "        self.ksize = ksize\n",
    "        pad = ksize // 2\n",
    "        self.pad = pad\n",
    "        self.inp = inp\n",
    "        self.group = group\n",
    "\n",
    "        if stride == 2:\n",
    "            outputs = oup - inp\n",
    "        else:\n",
    "            outputs = oup\n",
    "\n",
    "        branch_main_1 = [\n",
    "            # pw\n",
    "            nn.Conv2d(inp, mid_channels, 1, 1, 0, groups=group, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # dw\n",
    "            nn.Conv2d(mid_channels,\n",
    "                      mid_channels,\n",
    "                      ksize,\n",
    "                      stride,\n",
    "                      pad,\n",
    "                      groups=mid_channels,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "        ]\n",
    "        branch_main_2 = [\n",
    "            # pw-linear\n",
    "            nn.Conv2d(mid_channels, outputs, 1, 1, 0, groups=group,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(outputs),\n",
    "        ]\n",
    "        self.branch_main_1 = nn.Sequential(*branch_main_1)\n",
    "        self.branch_main_2 = nn.Sequential(*branch_main_2)\n",
    "\n",
    "        if stride == 2:\n",
    "            self.branch_proj = nn.AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, old_x):\n",
    "        x = old_x\n",
    "        x_proj = old_x\n",
    "        x = self.branch_main_1(x)\n",
    "        if self.group > 1:\n",
    "            x = self.channel_shuffle(x)\n",
    "        x = self.branch_main_2(x)\n",
    "        if self.stride == 1:\n",
    "            return F.relu(x + x_proj)\n",
    "        elif self.stride == 2:\n",
    "            return torch.cat((self.branch_proj(x_proj), F.relu(x)), 1)\n",
    "\n",
    "    def channel_shuffle(self, x):\n",
    "        batchsize, num_channels, height, width = x.data.size()\n",
    "        assert num_channels % self.group == 0\n",
    "        group_channels = num_channels // self.group\n",
    "\n",
    "        x = x.reshape(batchsize, group_channels, self.group, height, width)\n",
    "        x = x.permute(0, 2, 1, 3, 4)\n",
    "        x = x.reshape(batchsize, num_channels, height, width)\n",
    "\n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
