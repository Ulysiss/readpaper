{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMO\n",
    "\n",
    "做的改动主要集中在layer、EBlock和DBlock，故仅仅展示这些代码。\n",
    "\n",
    "**数据集：GoPro**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img src=./img/Architecture.jpg />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, stride, bias=True, norm=False, relu=True, transpose=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        if bias and norm:\n",
    "            bias = False\n",
    "\n",
    "        padding = kernel_size // 2\n",
    "        layers = list()\n",
    "        if transpose:\n",
    "            padding = kernel_size // 2 -1\n",
    "            layers.append(nn.ConvTranspose2d(in_channel, out_channel, kernel_size, padding=padding, stride=stride, bias=bias))\n",
    "        else:\n",
    "            layers.append(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size, padding=padding, stride=stride, bias=bias))\n",
    "        if norm:\n",
    "            layers.append(nn.BatchNorm2d(out_channel))\n",
    "        if relu:\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        self.main = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            BasicConv(in_channel, out_channel, kernel_size=3, stride=1, relu=True),\n",
    "            BasicConv(out_channel, out_channel, kernel_size=3, stride=1, relu=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x) + x\n",
    "\n",
    "\n",
    "class EBlock(nn.Module):\n",
    "    def __init__(self, out_channel, num_res=8):\n",
    "        super(EBlock, self).__init__()\n",
    "\n",
    "        layers = [ResBlock(out_channel, out_channel) for _ in range(num_res)]\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class DBlock(nn.Module):\n",
    "    def __init__(self, channel, num_res=8):\n",
    "        super(DBlock, self).__init__()\n",
    "\n",
    "        layers = [ResBlock(channel, channel) for _ in range(num_res)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## result\n",
    "<div align=center>\n",
    "<img src=./img/model_0.png />\n",
    "</div>\n",
    "\n",
    "**params:6.807M**\n",
    "\n",
    "**flops:67.094G**\n",
    "\n",
    "**数据集：GoPro**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model_1\n",
    "这个模型仅仅是将layer里的，标准卷积转为深度可分离卷积。其他均不改变。\n",
    "\n",
    "实验目的：测试深度可分离卷积替换卷积后，模型效果及计算量。\n",
    "\n",
    "**数据集：GoPro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, stride, bias=True, norm=False, relu=True, transpose=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        if bias and norm:\n",
    "            bias = False\n",
    "\n",
    "        padding = kernel_size // 2\n",
    "        layers = list()\n",
    "        if transpose:\n",
    "            padding = kernel_size // 2 -1\n",
    "            layers.append(nn.ConvTranspose2d(in_channel, out_channel, kernel_size, padding=padding, stride=stride, bias=bias))\n",
    "        else:\n",
    "            layers.append(\n",
    "                          nn.Conv2d(in_channel, in_channel, kernel_size, padding=padding, groups=in_channel ,stride=stride, bias=bias))\n",
    "            layers.append(nn.Conv2d(in_channel,out_channel,kernel_size=1))\n",
    "        if norm:\n",
    "            layers.append(nn.BatchNorm2d(out_channel))\n",
    "        if relu:\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        self.main = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## result\n",
    "<div align=center>\n",
    "<img src=./img/model_1.png width=\"1200px\"/>\n",
    "</div>\n",
    "\n",
    "**params:1.048M**\n",
    "\n",
    "**flops:13.786G**\n",
    "\n",
    "**数据集：GoPro**\n",
    "\n",
    "结果：模型性能下降，计算量下降。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model_2\n",
    "模型结构：在ResBlock中加入FFT。\n",
    "\n",
    "实验目的：探索FFT对模型提升效果。\n",
    "\n",
    "**数据集：GoPro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    #'Backward' means no normalize (just fft). \n",
    "    # 'Ortho' means the frequency matrix will normalize by 1/sqrt(n).\n",
    "    def __init__(self, n_feat,norm='backward'): # 'ortho'\n",
    "        super(ResBlock, self).__init__()\n",
    "        kernel_size=3\n",
    "        self.main = nn.Sequential(\n",
    "            BasicConv(n_feat, n_feat, kernel_size=kernel_size, stride=1, relu=True),\n",
    "            BasicConv(n_feat, n_feat, kernel_size=kernel_size, stride=1, relu=False)\n",
    "        )\n",
    "        self.main_fft = nn.Sequential(\n",
    "            BasicConv(n_feat*2, n_feat*2, kernel_size=1, stride=1, relu=True),\n",
    "            BasicConv(n_feat*2, n_feat*2, kernel_size=1, stride=1, relu=False)\n",
    "        )\n",
    "        self.dim = n_feat\n",
    "        self.norm = norm\n",
    "    def forward(self, x):\n",
    "        _, _, H, W = x.shape\n",
    "        dim = 1\n",
    "        y = torch.fft.rfft2(x, norm='backward')\n",
    "        y_imag = y.imag\n",
    "        y_real = y.real\n",
    "        y_f = torch.cat([y_real, y_imag], dim=dim)\n",
    "        y = self.main_fft(y_f)\n",
    "        y_real, y_imag = torch.chunk(y, 2, dim=dim)\n",
    "        y = torch.complex(y_real, y_imag)\n",
    "        y = torch.fft.irfft2(y, s=(H, W), norm='backward')\n",
    "        return self.main(x) + x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## result\n",
    "<div align=center>\n",
    "<img src=./img/model_2.png width=\"1200px\"/>\n",
    "</div>\n",
    "\n",
    "**params:3.843M**\n",
    "\n",
    "**flops:27.263G**\n",
    "\n",
    "**数据集：GoPro**\n",
    "\n",
    "结果：模型性能相对model_1,psnr值上升0.4，flops上升一倍。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model_3\n",
    "模型结构：相对model_2，增加EBlock、DBlock、feat_extract卷积核大小\n",
    "\n",
    "实验目的：受论文《Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs》启发，验证深度可分离卷积搭配大的卷积核效果。\n",
    "\n",
    "**数据集：GoPro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    #'Backward' means no normalize (just fft). \n",
    "    # 'Ortho' means the frequency matrix will normalize by 1/sqrt(n).\n",
    "    def __init__(self, n_feat,norm='backward'): # 'ortho'\n",
    "        super(ResBlock, self).__init__()\n",
    "        kernel_size=7\n",
    "        self.main = nn.Sequential(\n",
    "            BasicConv(n_feat, n_feat, kernel_size=kernel_size, stride=1, relu=True),\n",
    "            BasicConv(n_feat, n_feat, kernel_size=kernel_size, stride=1, relu=False)\n",
    "        )\n",
    "        self.main_fft = nn.Sequential(\n",
    "            BasicConv(n_feat*2, n_feat*2, kernel_size=1, stride=1, relu=True),\n",
    "            BasicConv(n_feat*2, n_feat*2, kernel_size=1, stride=1, relu=False)\n",
    "        )\n",
    "        self.dim = n_feat\n",
    "        self.norm = norm\n",
    "    def forward(self, x):\n",
    "        _, _, H, W = x.shape\n",
    "        dim = 1\n",
    "        y = torch.fft.rfft2(x, norm='backward')\n",
    "        y_imag = y.imag\n",
    "        y_real = y.real\n",
    "        y_f = torch.cat([y_real, y_imag], dim=dim)\n",
    "        y = self.main_fft(y_f)\n",
    "        y_real, y_imag = torch.chunk(y, 2, dim=dim)\n",
    "        y = torch.complex(y_real, y_imag)\n",
    "        y = torch.fft.irfft2(y, s=(H, W), norm='backward')\n",
    "        return self.main(x) + x + y\n",
    "\n",
    "kernel_size=7\n",
    "base_channel=32\n",
    "feat_extract = nn.ModuleList([\n",
    "        BasicConv(3, base_channel, kernel_size=kernel_size, relu=True, stride=1),\n",
    "        BasicConv(base_channel, base_channel * 2, kernel_size=kernel_size, relu=True, stride=2),\n",
    "        BasicConv(base_channel * 2, base_channel * 4, kernel_size=kernel_size, relu=True, stride=2),\n",
    "        BasicConv(base_channel * 4, base_channel * 2, kernel_size=kernel_size+1, relu=True, stride=2, transpose=True),\n",
    "        BasicConv(base_channel * 2, base_channel, kernel_size=kernel_size+1, relu=True, stride=2, transpose=True),\n",
    "        BasicConv(base_channel, 3, kernel_size=kernel_size, relu=False, stride=1)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## result\n",
    "<div align=center>\n",
    "<img src=./img/model_3.png width=\"1200px\"/>\n",
    "</div>\n",
    "\n",
    "**params:4.627M**\n",
    "\n",
    "**flops:44.968G**\n",
    "\n",
    "\n",
    "结果：模型性能相对model_2,psnr值上升0.2，flops上升17G。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model_10\n",
    "模型结构：ResBlock，Wavelet_transform，DB_kernel=7，EB_kernel=7,feat_extract_kernel=3\n",
    "<div align=center>\n",
    "<img src=./img/model_10_DB.png />\n",
    "</div>\n",
    "\n",
    "**数据集：REDS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#小波变换\n",
    "class DWT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DWT, self).__init__()\n",
    "        self.requires_grad = False  \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dwt_init(x)\n",
    "\n",
    "    def dwt_init(self,x):\n",
    "        x01 = x[:, :, 0::2, :] / 2\n",
    "        x02 = x[:, :, 1::2, :] / 2\n",
    "        x1 = x01[:, :, :, 0::2]\n",
    "        x2 = x02[:, :, :, 0::2]\n",
    "        x3 = x01[:, :, :, 1::2]\n",
    "        x4 = x02[:, :, :, 1::2]\n",
    "        x_LL = x1 + x2 + x3 + x4\n",
    "        x_HL = -x1 - x2 + x3 + x4\n",
    "        x_LH = -x1 + x2 - x3 + x4\n",
    "        x_HH = x1 - x2 - x3 + x4\n",
    "        return torch.cat((x_LL, x_HL, x_LH, x_HH), 0)\n",
    "\n",
    "\n",
    "class IWT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IWT, self).__init__()\n",
    "        self.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.iwt_init(x)\n",
    "\n",
    "    def iwt_init(self,x):\n",
    "        r = 2\n",
    "        in_batch, in_channel, in_height, in_width = x.size()\n",
    "        #print([in_batch, in_channel, in_height, in_width])\n",
    "        out_batch, out_channel, out_height, out_width = int(in_batch / r ** 2), int(\n",
    "            in_channel), r * in_height, r * in_width\n",
    "        x1 = x[0:out_batch, :, :, :] / 2\n",
    "        x2 = x[out_batch:out_batch * 2, :, :, :] / 2\n",
    "        x3 = x[out_batch * 2:out_batch * 3, :, :, :] / 2\n",
    "        x4 = x[out_batch * 3:out_batch * 4, :, :, :] / 2\n",
    "\n",
    "        h = torch.zeros([out_batch, out_channel, out_height,out_width]).float().cuda()\n",
    "\n",
    "        h[:, :, 0::2, 0::2] = x1 - x2 - x3 + x4\n",
    "        h[:, :, 1::2, 0::2] = x1 - x2 + x3 - x4\n",
    "        h[:, :, 0::2, 1::2] = x1 + x2 - x3 - x4\n",
    "        h[:, :, 1::2, 1::2] = x1 + x2 + x3 + x4\n",
    "        return h\n",
    "\n",
    "class Wavelet_transform(nn.Module):\n",
    "    def __init__(self,in_channel,out_channel):\n",
    "        super(Wavelet_transform,self).__init__()\n",
    "        self.conv1 = BasicConv(in_channel, 64, kernel_size=5)\n",
    "        self.conv2 = BasicConv(64, 32, kernel_size=3)\n",
    "        self.conv3 = BasicConv(32, out_channel, kernel_size=3)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.DWT = DWT()\n",
    "        self.IDWT = IWT()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.DWT(x)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        x = self.IDWT(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EBlock(nn.Module):\n",
    "    def __init__(self, out_channel, num_res=8):\n",
    "        super(EBlock, self).__init__()\n",
    "\n",
    "        layers = [ResBlock(out_channel,out_channel,kernel_size=7) for _ in range(num_res)]\n",
    "        self.wavelet=Wavelet_transform(out_channel,out_channel)\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #return self.layers(x)\n",
    "        return self.layers(x)+self.wavelet(x)\n",
    "\n",
    "\n",
    "class DBlock(nn.Module):\n",
    "    def __init__(self, channel, num_res=8):\n",
    "        super(DBlock, self).__init__()\n",
    "\n",
    "        layers = [ResBlock(channel,channel,kernel_size=7) for _ in range(num_res)]\n",
    "        self.wavelet=Wavelet_transform(channel,channel)\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #return self.layers(x)\n",
    "        return self.layers(x)+self.wavelet(x)\n",
    "\n",
    "kernel_size=3\n",
    "base_channel=32\n",
    "feat_extract = nn.ModuleList([\n",
    "        BasicConv(3, base_channel, kernel_size=kernel_size, relu=True, stride=1),\n",
    "        BasicConv(base_channel, base_channel * 2, kernel_size=kernel_size, relu=True, stride=2),\n",
    "        BasicConv(base_channel * 2, base_channel * 4, kernel_size=kernel_size, relu=True, stride=2),\n",
    "        BasicConv(base_channel * 4, base_channel * 2, kernel_size=kernel_size+1, relu=True, stride=2, transpose=True),\n",
    "        BasicConv(base_channel * 2, base_channel, kernel_size=kernel_size+1, relu=True, stride=2, transpose=True),\n",
    "        BasicConv(base_channel, 3, kernel_size=kernel_size, relu=False, stride=1)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## result\n",
    "\n",
    "<div align=center>\n",
    "<img src=./img/model_10_REDS.png width=\"1200px\"/>\n",
    "</div>\n",
    "\n",
    "**params:1.408M**\n",
    "\n",
    "**flops:19.920G**\n",
    "\n",
    "<div>\n",
    "<img src=./img/model_10/90/patch_0_0.png width=\"600px\" />\n",
    "<img src=./img/model_10/120/patch_0_0.png width=\"600px\" />\n",
    "</div>\n",
    "\n",
    "缺陷：图像出现伪影\n",
    "\n",
    "<div>\n",
    "<img src=./img/model_10/90/patch_8_5.png width=\"600px\" />\n",
    "<img src=./img/model_10/120/patch_8_5.png width=\"600px\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model_10第二次训练\n",
    "实验目的：更换数据集，查看realBlur数据集的效果\n",
    "\n",
    "数据集：realBlur\n",
    "\n",
    "<div align=center>\n",
    "<img src=./img/model_10_realBlur.png width=\"1200px\"/>\n",
    "</div>\n",
    "\n",
    "<img src=./img/model_10_realBlur/350/patch_0_0.png width=\"600px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model_8\n",
    "数据集：REDS_JPEG\n",
    "\n",
    "在MIMO中加入dropout，原因：由于VIVO数据集和REDS数据集之间存在gap，导致部分图像出现伪影。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## result\n",
    "\n",
    "<div align=center>\n",
    "<img src=./img/model_8.png width=\"1200px\"/>\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "<img src=./img/model_8/140/patch_0_0.png width=\"600px\" />\n",
    "<img src=./img/model_8/140/patch_8_5.png width=\"600px\" />\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结\n",
    "\n",
    "目前效果最好的是使model_10基于REDS，第90epoch生成的图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resotrom：MDTA替换为GDFN 先测FLOPS\n",
    "mimo aff 1X1 3X3替换为GDFN 测FLOPS 没有小波变换 深度可分卷积\n",
    "数据集是REDS_JPEG"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
